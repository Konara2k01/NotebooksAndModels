{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:27:49.859404Z","iopub.status.busy":"2024-08-24T06:27:49.859112Z","iopub.status.idle":"2024-08-24T06:27:53.513680Z","shell.execute_reply":"2024-08-24T06:27:53.512640Z","shell.execute_reply.started":"2024-08-24T06:27:49.859372Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus: \n","    tf.config.experimental.set_memory_growth(gpu, True)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:27:53.523840Z","iopub.status.busy":"2024-08-24T06:27:53.523112Z","iopub.status.idle":"2024-08-24T06:27:53.688695Z","shell.execute_reply":"2024-08-24T06:27:53.687832Z","shell.execute_reply.started":"2024-08-24T06:27:53.523789Z"},"trusted":true},"outputs":[],"source":["import tensorflow_datasets as tfds"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:27:53.696968Z","iopub.status.busy":"2024-08-24T06:27:53.696599Z","iopub.status.idle":"2024-08-24T06:27:53.701843Z","shell.execute_reply":"2024-08-24T06:27:53.700900Z","shell.execute_reply.started":"2024-08-24T06:27:53.696925Z"},"trusted":true},"outputs":[],"source":["def scale_images(data): \n","    image = data['image']\n","    return image / 255"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:27:53.703312Z","iopub.status.busy":"2024-08-24T06:27:53.703029Z","iopub.status.idle":"2024-08-24T06:27:54.212986Z","shell.execute_reply":"2024-08-24T06:27:54.212178Z","shell.execute_reply.started":"2024-08-24T06:27:53.703281Z"},"trusted":true},"outputs":[],"source":["# Reload the dataset \n","ds = tfds.load('fashion_mnist', split='train')\n","# Running the dataset through the scale_images preprocessing step\n","ds = ds.map(scale_images) \n","# Cache the dataset for that batch \n","ds = ds.cache()\n","# Shuffle it up \n","ds = ds.shuffle(60000)\n","# Batch into 128 images per sample\n","ds = ds.batch(128)\n","# Reduces the likelihood of bottlenecking \n","ds = ds.prefetch(64)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:27:54.214450Z","iopub.status.busy":"2024-08-24T06:27:54.214166Z","iopub.status.idle":"2024-08-24T06:27:54.232790Z","shell.execute_reply":"2024-08-24T06:27:54.231713Z","shell.execute_reply.started":"2024-08-24T06:27:54.214420Z"},"trusted":true},"outputs":[],"source":["# Bring in the sequential api for the generator and discriminator\n","from tensorflow.keras.models import Sequential\n","# Bring in the layers for the neural network\n","from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:27:54.234397Z","iopub.status.busy":"2024-08-24T06:27:54.234105Z","iopub.status.idle":"2024-08-24T06:27:54.243165Z","shell.execute_reply":"2024-08-24T06:27:54.242181Z","shell.execute_reply.started":"2024-08-24T06:27:54.234365Z"},"trusted":true},"outputs":[],"source":["def build_generator(): \n","    model = Sequential()\n","    \n","    # Takes in random values and reshapes it to 7x7x128\n","    # Beginnings of a generated image\n","    model.add(Dense(7*7*128, input_dim=128))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Reshape((7,7,128)))\n","    \n","    # Upsampling block 1 \n","    model.add(UpSampling2D())\n","    model.add(Conv2D(128, 5, padding='same'))\n","    model.add(LeakyReLU(0.2))\n","    \n","    # Upsampling block 2 \n","    model.add(UpSampling2D())\n","    model.add(Conv2D(128, 5, padding='same'))\n","    model.add(LeakyReLU(0.2))\n","    \n","    # Convolutional block 1\n","    model.add(Conv2D(128, 4, padding='same'))\n","    model.add(LeakyReLU(0.2))\n","    \n","    # Convolutional block 2\n","    model.add(Conv2D(128, 4, padding='same'))\n","    model.add(LeakyReLU(0.2))\n","    \n","    # Conv layer to get to one channel\n","    model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))\n","    \n","    return model"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:27:54.244640Z","iopub.status.busy":"2024-08-24T06:27:54.244360Z","iopub.status.idle":"2024-08-24T06:27:54.253488Z","shell.execute_reply":"2024-08-24T06:27:54.252460Z","shell.execute_reply.started":"2024-08-24T06:27:54.244609Z"},"trusted":true},"outputs":[],"source":["def build_discriminator(): \n","    model = Sequential()\n","    \n","    # First Conv Block\n","    model.add(Conv2D(32, 5, input_shape = (28,28,1)))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Dropout(0.4))\n","    \n","    # Second Conv Block\n","    model.add(Conv2D(64, 5))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Dropout(0.4))\n","    \n","    # Third Conv Block\n","    model.add(Conv2D(128, 5))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Dropout(0.4))\n","    \n","    # Fourth Conv Block\n","    model.add(Conv2D(256, 5))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Dropout(0.4))\n","    \n","    # Flatten then pass to dense layer\n","    model.add(Flatten())\n","    model.add(Dropout(0.4))\n","    model.add(Dense(1, activation='sigmoid'))\n","    \n","    return model "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:27:54.255279Z","iopub.status.busy":"2024-08-24T06:27:54.254976Z","iopub.status.idle":"2024-08-24T06:27:54.264997Z","shell.execute_reply":"2024-08-24T06:27:54.264090Z","shell.execute_reply.started":"2024-08-24T06:27:54.255240Z"},"trusted":true},"outputs":[],"source":["# Adam is going to be the optimizer for both\n","from tensorflow.keras.optimizers import Adam\n","# Binary cross entropy is going to be the loss for both \n","from tensorflow.keras.losses import BinaryCrossentropy"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:27:54.268707Z","iopub.status.busy":"2024-08-24T06:27:54.268347Z","iopub.status.idle":"2024-08-24T06:27:54.284867Z","shell.execute_reply":"2024-08-24T06:27:54.283990Z","shell.execute_reply.started":"2024-08-24T06:27:54.268670Z"},"trusted":true},"outputs":[],"source":["g_opt = Adam(learning_rate=0.0001) \n","d_opt = Adam(learning_rate=0.00001) \n","g_loss = BinaryCrossentropy()\n","d_loss = BinaryCrossentropy()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:27:54.286558Z","iopub.status.busy":"2024-08-24T06:27:54.286194Z","iopub.status.idle":"2024-08-24T06:27:54.305108Z","shell.execute_reply":"2024-08-24T06:27:54.304185Z","shell.execute_reply.started":"2024-08-24T06:27:54.286517Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import Model\n","\n","class FashionGAN(Model): \n","    def __init__(self, generator, discriminator, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        \n","        self.generator = generator \n","        self.discriminator = discriminator \n","        \n","    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs): \n","        super().compile(*args, **kwargs)\n","        \n","        self.g_opt = g_opt\n","        self.d_opt = d_opt\n","        self.g_loss = g_loss\n","        self.d_loss = d_loss \n","\n","    def train_step(self, batch):\n","        real_images = batch\n","        fake_images = self.generator(tf.random.normal((128, 128, 1)), training=False)\n","        \n","        with tf.GradientTape() as d_tape: \n","            yhat_real = self.discriminator(real_images, training=True) \n","            yhat_fake = self.discriminator(fake_images, training=True)\n","            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n","            \n","            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n","            \n","            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n","            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n","            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n","            \n","            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n","            \n","        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables) \n","        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n","        \n","        with tf.GradientTape() as g_tape: \n","            gen_images = self.generator(tf.random.normal((128,128,1)), training=True)\n","            predicted_labels = self.discriminator(gen_images, training=False)\n","                                        \n","            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels) \n","            \n","        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n","        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n","        \n","        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:29:19.016394Z","iopub.status.busy":"2024-08-24T06:29:19.015970Z","iopub.status.idle":"2024-08-24T06:29:19.341568Z","shell.execute_reply":"2024-08-24T06:29:19.340463Z","shell.execute_reply.started":"2024-08-24T06:29:19.016354Z"},"trusted":true},"outputs":[],"source":["# Initialize the strategy\n","strategy = tf.distribute.MirroredStrategy()\n","\n","# Use the strategy scope to create and compile the models\n","with strategy.scope():\n","    # Build the generator and discriminator models\n","    generator = build_generator()\n","    discriminator = build_discriminator()\n","\n","    # Define the optimizers inside the strategy scope\n","    g_opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","    d_opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n","\n","    # Define the loss functions\n","    g_loss = tf.keras.losses.BinaryCrossentropy()\n","    d_loss = tf.keras.losses.BinaryCrossentropy()\n","\n","    # Initialize and compile the GAN model\n","    gan = FashionGAN(generator, discriminator)\n","    gan.compile(g_opt=g_opt, d_opt=d_opt, g_loss=g_loss, d_loss=d_loss)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T06:29:27.725505Z","iopub.status.busy":"2024-08-24T06:29:27.724573Z","iopub.status.idle":"2024-08-24T06:56:25.634240Z","shell.execute_reply":"2024-08-24T06:56:25.633236Z","shell.execute_reply.started":"2024-08-24T06:29:27.725463Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n"]},{"name":"stderr","output_type":"stream","text":["2024-08-24 06:29:37.765311: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/cond/else/_186/cond/StatefulPartitionedCall/replica_1/sequential_3_1/dropout_5_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 166ms/step - d_loss: 0.5565 - g_loss: 1.1821\n","Epoch 2/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 166ms/step - d_loss: 0.5351 - g_loss: 2.6954\n","Epoch 3/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 169ms/step - d_loss: 0.4563 - g_loss: 4.4820\n","Epoch 4/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 170ms/step - d_loss: 0.4692 - g_loss: 4.1646\n","Epoch 5/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 170ms/step - d_loss: 0.4440 - g_loss: 4.0367\n","Epoch 6/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 170ms/step - d_loss: 0.4576 - g_loss: 3.6683\n","Epoch 7/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 170ms/step - d_loss: 0.4571 - g_loss: 3.4835\n","Epoch 8/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 171ms/step - d_loss: 0.6049 - g_loss: 1.1761\n","Epoch 9/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 170ms/step - d_loss: 0.5785 - g_loss: 1.0496\n","Epoch 10/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 170ms/step - d_loss: 0.4794 - g_loss: 0.8526\n","Epoch 11/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 170ms/step - d_loss: 0.4909 - g_loss: 0.8688\n","Epoch 12/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 170ms/step - d_loss: 0.4698 - g_loss: 0.6960\n","Epoch 13/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 170ms/step - d_loss: 0.4511 - g_loss: 0.6736\n","Epoch 14/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 170ms/step - d_loss: 0.3290 - g_loss: 0.3818\n","Epoch 15/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 171ms/step - d_loss: 0.3300 - g_loss: 0.2337\n","Epoch 16/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 171ms/step - d_loss: 0.3017 - g_loss: 0.1611\n","Epoch 17/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 171ms/step - d_loss: 0.3246 - g_loss: 0.1664\n","Epoch 18/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 171ms/step - d_loss: 0.6419 - g_loss: 0.5696\n","Epoch 19/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 171ms/step - d_loss: 0.6426 - g_loss: 0.8142\n","Epoch 20/20\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 171ms/step - d_loss: 0.6466 - g_loss: 0.8318\n"]}],"source":["hist = gan.fit(ds, epochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"isSourceIdPinned":true,"modelId":108429,"modelInstanceId":84179,"sourceId":100353,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
